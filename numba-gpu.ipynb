{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba GPU nó Sequana (sdumont18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>, <Managed Device 1>, <Managed Device 2>, <Managed Device 3>\n"
     ]
    }
   ],
   "source": [
    "# Check if Cuda is active\n",
    "from numba import cuda\n",
    "print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU(s):                88\n",
      "Thread(s) per core:    2\n",
      "Core(s) per socket:    22\n",
      "NUMA node(s):          2\n",
      "Model name:            Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz\n",
      "CPU MHz:               2101.000\n"
     ]
    }
   ],
   "source": [
    "! lscpu | head -n 15 | grep \"Model \\|CPU(s):\\|Thre\\|Core\\|NUMA\\|MHz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 17 16:09:06 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    41W / 250W |   2089MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    26W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    24W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    25W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     23202      C   ...conda3/2020.11/bin/python      493MiB |\n",
      "|    0   N/A  N/A     81546      C   ...sions/3.8.7/bin/python3.8      309MiB |\n",
      "|    0   N/A  N/A    116950      C   ...sions/3.8.7/bin/python3.8     1283MiB |\n",
      "|    1   N/A  N/A     23202      C   ...conda3/2020.11/bin/python        0MiB |\n",
      "|    1   N/A  N/A     81546      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "|    1   N/A  N/A    116950      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "|    2   N/A  N/A     23202      C   ...conda3/2020.11/bin/python        0MiB |\n",
      "|    2   N/A  N/A     81546      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "|    2   N/A  N/A    116950      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "|    3   N/A  N/A     23202      C   ...conda3/2020.11/bin/python        0MiB |\n",
      "|    3   N/A  N/A     81546      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "|    3   N/A  N/A    116950      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.5087 | Kernel: 0.4278 | Memory: 0.0749\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, math\n",
    "from time import time\n",
    "from numba import cuda\n",
    "\n",
    "# parameters\n",
    "n            = 2400    # nxn grid\n",
    "energy       = 1       # energy to be injected per iteration\n",
    "niters       = 250     # number of iterations\n",
    "# initialize the data arrays\n",
    "anew         = np.zeros((n + 2, n + 2), np.float64)\n",
    "aold         = np.zeros((n + 2, n + 2), np.float64)\n",
    "# initialize three heat sources\n",
    "nsources     = 3       # sources of energy\n",
    "sources      = np.empty((nsources,2), np.int32)\n",
    "sources[:,:] = [ [n//2, n//2], [n//3, n//3], [n*4//5, n*8//9] ]\n",
    "sources      = [ [n//2, n//2], [n//3, n//3], [n*4//5, n*8//9] ]\n",
    "heat         = 0       # system total heat sum\n",
    "\n",
    "# configure blocks & grids\n",
    "## set the number of threads in a block\n",
    "threads_per_block = (8, 8)\n",
    "## calculate the number of thread blocks in the grid\n",
    "blocks_per_grid_x = math.ceil(aold.shape[0] / threads_per_block[0])\n",
    "blocks_per_grid_y = math.ceil(aold.shape[1] / threads_per_block[1])\n",
    "blocks_per_grid   = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "# computationally intensive core\n",
    "@cuda.jit\n",
    "def kernel(a1, a2) :\n",
    "    n = a1.shape[0] - 1\n",
    "    i, j = cuda.grid(2)\n",
    "    if (i > 0 and j > 0) and (i < n and j < n) :\n",
    "        a1[i,j] = 1/2.0*(a2[i,j]+\n",
    "                  1/4.0*(a2[i-1,j]+a2[i+1,j]+a2[i,j-1]+a2[i,j+1]))\n",
    "\n",
    "# insert heat\n",
    "@cuda.jit\n",
    "def insert_heat(a, sources, energy) :\n",
    "    n = a.shape[0] - 1\n",
    "    i, j = cuda.grid(2)\n",
    "    if ( (sources[0, 0] == i and sources[0, 1] == j) or\n",
    "         (sources[1, 0] == i and sources[1, 1] == j) or\n",
    "         (sources[2, 0] == i and sources[2, 1] == j) ) :\n",
    "        a[i, j] += energy\n",
    "\n",
    "# main routine\n",
    "t0 = time()    # time measure\n",
    "t1 = 0\n",
    "t2 = 0\n",
    "\n",
    "t_ = time()\n",
    "# copy the arrays to the device\n",
    "anew_global_mem    = cuda.to_device(anew)\n",
    "aold_global_mem    = cuda.to_device(aold)\n",
    "sources_global_mem = cuda.to_device(sources)\n",
    "t2 += time() - t_\n",
    "\n",
    "for _ in range(0, niters, 2) :\n",
    "    t_ = time()\n",
    "    kernel[blocks_per_grid, threads_per_block](\n",
    "        anew_global_mem, aold_global_mem)\n",
    "    insert_heat[blocks_per_grid, threads_per_block](\n",
    "        anew_global_mem, sources_global_mem, energy)    \n",
    "    kernel[blocks_per_grid, threads_per_block](\n",
    "        aold_global_mem, anew_global_mem)\n",
    "    insert_heat[blocks_per_grid, threads_per_block](\n",
    "        aold_global_mem, sources_global_mem, energy)\n",
    "    t1 += time() - t_\n",
    "\n",
    "t_ = time()\n",
    "# copy the result back to the host\n",
    "aold = aold_global_mem.copy_to_host()\n",
    "t2 += time() - t_\n",
    "\n",
    "# system total heat\n",
    "heat = np.sum( aold[1:-1, 1:-1] )\n",
    "\n",
    "t0 = time() - t0\n",
    "\n",
    "# show result\n",
    "print(\"Heat: %0.4f | Time: %0.4f | Kernel: %0.4f | Memory: %0.4f\" %\n",
    "      (heat, t0, t1, t2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação com Numba CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting numbacpusequana.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile numbacpusequana.py\n",
    "import numpy as np, sys\n",
    "from time import time\n",
    "from numba import njit, set_num_threads, get_num_threads, threading_layer\n",
    "\n",
    "# parameters\n",
    "n            = 2400    # n x n grid\n",
    "energy       = 1.0     # energy to be injected per iteration\n",
    "niters       = 250     # number of iterations\n",
    "\n",
    "# other variables\n",
    "heat         = np.zeros((1), np.float64)     # system total heat\n",
    "anew         = np.zeros((n + 2,  n + 2), np.float64)\n",
    "aold         = np.zeros((n + 2,  n + 2), np.float64)\n",
    "sources      = np.empty((3, 2), np.int16)    # sources of energy\n",
    "sources[:,:] = [ [n//2, n//2], [n//3, n//3], [n*4//5, n*8//9] ]\n",
    "\n",
    "# computationally intensive core\n",
    "@njit('(float64[:,:],float64[:,:])', fastmath=True, parallel=True, nogil=True)\n",
    "def kernel(anew, aold) :\n",
    "    anew[1:-1,1:-1]=1/2.0*(aold[1:-1,1:-1]+1/4.0*(aold[2:,1:-1]+aold[:-2,1:-1]+aold[1:-1,2:]+aold[1:-1,:-2]))\n",
    "\n",
    "# main routine\n",
    "set_num_threads(int(sys.argv[1]))\n",
    "t2 = 0\n",
    "t0 = time()    # time measure\n",
    "for iters in range((niters+1)//2) :\n",
    "    t3 = time()\n",
    "    kernel(anew, aold)\n",
    "    t2 += time() - t3\n",
    "    anew[sources[:, 0], sources[:, 1]] += energy\n",
    "    t3 = time()\n",
    "    kernel(aold, anew)\n",
    "    t2 += time() - t3\n",
    "    aold[sources[:, 0], sources[:, 1]] += energy\n",
    "heat[0] = np.sum( aold[1:-1, 1:-1] )  # system total heat\n",
    "t1 = time()    # time measure\n",
    "\n",
    "# show result\n",
    "print(\"Heat: %0.4f | Time: %0.4f | Kernel: %0.4f\" % (heat[0], t1-t0, t2) )\n",
    "print(\"Threading layer chosen: %s | Thread count: %s\" % (threading_layer(), get_num_threads()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1, 4, 9, 16, 36, 49, 64, 81, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 2.1131 | Kernel: 2.1012\n",
      "Threading layer chosen: tbb | Thread count: 1\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.8060 | Kernel: 0.7942\n",
      "Threading layer chosen: tbb | Thread count: 4\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.4837 | Kernel: 0.4734\n",
      "Threading layer chosen: tbb | Thread count: 9\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3704 | Kernel: 0.3599\n",
      "Threading layer chosen: tbb | Thread count: 16\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 36 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3639 | Kernel: 0.3493\n",
      "Threading layer chosen: tbb | Thread count: 36\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 49 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3608 | Kernel: 0.3471\n",
      "Threading layer chosen: tbb | Thread count: 49\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 64 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3662 | Kernel: 0.3515\n",
      "Threading layer chosen: tbb | Thread count: 64\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 81 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3710 | Kernel: 0.3557\n",
      "Threading layer chosen: tbb | Thread count: 81\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 88 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3708 | Kernel: 0.3552\n",
      "Threading layer chosen: tbb | Thread count: 88\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"numbacpusequana.py\", line 23, in <module>\n",
      "    set_num_threads(int(sys.argv[1]))\n",
      "  File \"/scratch/app/anaconda3/2020.11/lib/python3.8/site-packages/numba/np/ufunc/parallel.py\", line 577, in set_num_threads\n",
      "    snt_check(n)\n",
      "  File \"/scratch/app/anaconda3/2020.11/lib/python3.8/site-packages/numba/np/ufunc/parallel.py\", line 539, in snt_check\n",
      "    raise ValueError(msg)\n",
      "ValueError: The number of threads must be between 1 and 88\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
