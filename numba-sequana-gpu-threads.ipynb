{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba GPU nó Sequana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>, <Managed Device 1>, <Managed Device 2>, <Managed Device 3>\n"
     ]
    }
   ],
   "source": [
    "# Check if Cuda is active\n",
    "from numba import cuda\n",
    "print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU(s):                88\n",
      "Thread(s) per core:    2\n",
      "Core(s) per socket:    22\n",
      "NUMA node(s):          2\n",
      "Model name:            Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz\n",
      "CPU MHz:               2101.000\n"
     ]
    }
   ],
   "source": [
    "! lscpu | head -n 15 | grep \"Model \\|CPU(s):\\|Thre\\|Core\\|NUMA\\|MHz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 23 21:15:41 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   52C    P0    42W / 250W |   1596MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    26W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    25W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    25W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     81546      C   ...sions/3.8.7/bin/python3.8      309MiB |\n",
      "|    0   N/A  N/A    116950      C   ...sions/3.8.7/bin/python3.8     1283MiB |\n",
      "|    1   N/A  N/A     81546      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "|    1   N/A  N/A    116950      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "|    2   N/A  N/A     81546      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "|    2   N/A  N/A    116950      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "|    3   N/A  N/A     81546      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "|    3   N/A  N/A    116950      C   ...sions/3.8.7/bin/python3.8        0MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 4.7038 | Kernel: 4.4812 | Memory: 0.2163\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, math\n",
    "from time import time\n",
    "from numba import cuda\n",
    "\n",
    "# parameters\n",
    "n            = 2400    # nxn grid\n",
    "energy       = 1       # energy to be injected per iteration\n",
    "niters       = 250     # number of iterations\n",
    "# initialize the data arrays\n",
    "anew         = np.zeros((n + 2, n + 2), np.float64)\n",
    "aold         = np.zeros((n + 2, n + 2), np.float64)\n",
    "# initialize three heat sources\n",
    "sources      = np.empty((3, 2), np.int16)\n",
    "sources[:,:] = [ [n//2, n//2], [n//3, n//3], [n*4//5, n*8//9] ]\n",
    "\n",
    "# configure blocks & grids\n",
    "## set the number of threads in a block\n",
    "threads_per_block = (8, 8)\n",
    "## calculate the number of thread blocks in the grid\n",
    "blocks_per_grid_x = math.ceil(aold.shape[0] / threads_per_block[0])\n",
    "blocks_per_grid_y = math.ceil(aold.shape[1] / threads_per_block[1])\n",
    "blocks_per_grid   = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "# computationally intensive core\n",
    "@cuda.jit\n",
    "def kernel(a1, a2) :\n",
    "    n = a1.shape[0] - 1\n",
    "    i, j = cuda.grid(2)\n",
    "    if (i > 0 and j > 0) and (i < n and j < n) :\n",
    "        a1[i,j] = (a2[i,j]/2.0\n",
    "                   +(a2[i-1,j]+a2[i+1,j]+a2[i,j-1]+a2[i,j+1])/8.0)\n",
    "\n",
    "# insert heat\n",
    "@cuda.jit\n",
    "def insert_heat(a, sources, energy) :\n",
    "    n = a.shape[0] - 1\n",
    "    i, j = cuda.grid(2)\n",
    "    if ( (sources[0, 0] == i and sources[0, 1] == j) or\n",
    "         (sources[1, 0] == i and sources[1, 1] == j) or\n",
    "         (sources[2, 0] == i and sources[2, 1] == j) ) :\n",
    "        a[i, j] += energy\n",
    "\n",
    "# main routine\n",
    "t0 = -time()    # time measure\n",
    "t1 = 0\n",
    "t2 = 0\n",
    "\n",
    "t_ = time()\n",
    "# copy the arrays to the device\n",
    "anew_global_mem    = cuda.to_device(anew)\n",
    "aold_global_mem    = cuda.to_device(aold)\n",
    "sources_global_mem = cuda.to_device(sources)\n",
    "t2 += time() - t_\n",
    "\n",
    "for _ in range(0, niters, 2) :\n",
    "    t_ = time()\n",
    "    kernel[blocks_per_grid, threads_per_block](\n",
    "        anew_global_mem, aold_global_mem)\n",
    "    insert_heat[blocks_per_grid, threads_per_block](\n",
    "        anew_global_mem, sources_global_mem, energy)    \n",
    "    kernel[blocks_per_grid, threads_per_block](\n",
    "        aold_global_mem, anew_global_mem)\n",
    "    insert_heat[blocks_per_grid, threads_per_block](\n",
    "        aold_global_mem, sources_global_mem, energy)\n",
    "    t1 += time() - t_\n",
    "\n",
    "t_ = time()\n",
    "# copy the result back to the host\n",
    "aold = aold_global_mem.copy_to_host()\n",
    "t2 += time() - t_\n",
    "\n",
    "# system total heat\n",
    "heat = np.sum(aold[1:-1, 1:-1])\n",
    "\n",
    "t0 += time()\n",
    "\n",
    "# show the result\n",
    "print(f\"Heat: {heat:.4f}\", end=\" | \")\n",
    "print(f\"Time: {t0:.4f}\", end=\" | \")\n",
    "print(f\"Kernel: {t1:.4f}\", end=\" | \")\n",
    "print(f\"Memory: {t2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação com Numba CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting numbacpusequana.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile numbacpusequana.py\n",
    "import numpy as np, sys\n",
    "from time import time\n",
    "from numba import njit, set_num_threads, get_num_threads, threading_layer\n",
    "\n",
    "# parameters\n",
    "n            = 2400    # n x n grid\n",
    "energy       = 1.0     # energy to be injected per iteration\n",
    "niters       = 250     # number of iterations\n",
    "# initialize the data arrays\n",
    "anew         = np.zeros((n + 2,  n + 2), np.float64)\n",
    "aold         = np.zeros((n + 2,  n + 2), np.float64)\n",
    "# initialize three heat sources\n",
    "sources      = np.empty((3, 2), np.int16)    # sources of energy\n",
    "sources[:,:] = [ [n//2, n//2], [n//3, n//3], [n*4//5, n*8//9] ]\n",
    "\n",
    "# computationally intensive core\n",
    "@njit('(float64[:,:],float64[:,:])', parallel=True, fastmath=True, nogil=True)\n",
    "def kernel(anew, aold) :\n",
    "    anew[1:-1,1:-1] = (aold[1:-1,1:-1]/2.0\n",
    "        +(aold[2:,1:-1]+aold[:-2,1:-1]+aold[1:-1,2:]+aold[1:-1,:-2])/8.0)\n",
    "\n",
    "# main routine\n",
    "set_num_threads(int(sys.argv[1]))\n",
    "t0 = -time()    # time measure\n",
    "t1 = 0\n",
    "for _ in range(0, niters, 2) :\n",
    "    t_ = time()\n",
    "    kernel(anew, aold)\n",
    "    t1 += time() - t_\n",
    "    anew[sources[:, 0], sources[:, 1]] += energy\n",
    "    t_ = time()\n",
    "    kernel(aold, anew)\n",
    "    t1 += time() - t_\n",
    "    aold[sources[:, 0], sources[:, 1]] += energy\n",
    "heat = np.sum(aold[1:-1, 1:-1])  # system total heat\n",
    "t0 += time()    # time measure\n",
    "\n",
    "# show the result\n",
    "print(f\"Heat: {heat:.4f}\", end=\" | \")\n",
    "print(f\"Time: {t0:.4f}\", end=\" | \")\n",
    "print(f\"Kernel: {t1:.4f}\")\n",
    "print(f\"Threading layer: {threading_layer()}\", end=\" | \")\n",
    "print(f\"Thread count: {get_num_threads()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1, 4, 9, 16, 36, 49, 64, 81, 88\n",
    "* visualizar top em um terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 2.0726 | Kernel: 2.0615\n",
      "Threading layer: tbb | Thread count: 1\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.8354 | Kernel: 0.8231\n",
      "Threading layer: tbb | Thread count: 4\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3493 | Kernel: 0.3396\n",
      "Threading layer: tbb | Thread count: 16\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3143 | Kernel: 0.3025\n",
      "Threading layer: tbb | Thread count: 32\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 34 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3081 | Kernel: 0.2964\n",
      "Threading layer: tbb | Thread count: 34\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 44 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3731 | Kernel: 0.3582\n",
      "Threading layer: tbb | Thread count: 44\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 64 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3641 | Kernel: 0.3485\n",
      "Threading layer: tbb | Thread count: 64\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 88 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat: 750.0000 | Time: 0.3708 | Kernel: 0.3543\n",
      "Threading layer: tbb | Thread count: 88\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python numbacpusequana.py 88"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
